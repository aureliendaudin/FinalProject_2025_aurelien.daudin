{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this data analysis, we will focus on the interaction data, i.e., the data that contains the user-item interactions. If you make the choice to use the other data available, you should repeat the same kind of analysis on the other data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading small matrix...\n",
      "Loading big matrix...\n",
      "Loading item features...\n",
      "Loading captions...\n",
      "Loading items' daily features...\n",
      "All data loaded.\n"
     ]
    }
   ],
   "source": [
    "rootpath=\"./data_final_project/KuaiRec 2.0/\"\n",
    "\n",
    "print(\"Loading small matrix...\")\n",
    "small_matrix = pd.read_csv(rootpath + \"data/small_matrix.csv\")\n",
    "\n",
    "print(\"Loading big matrix...\")\n",
    "big_matrix = pd.read_csv(rootpath + \"data/big_matrix.csv\")\n",
    "\n",
    "print(\"Loading item features...\")\n",
    "item_categories = pd.read_csv(rootpath + \"data/item_categories.csv\")\n",
    "item_categories[\"feat\"] = item_categories[\"feat\"].map(eval)\n",
    "\n",
    "print(\"Loading captions...\") # captions contains chinese characters\n",
    "captions = pd.read_csv(rootpath + \"data/kuairec_caption_category.csv\", engine='python')\n",
    "\n",
    "print(\"Loading items' daily features...\")\n",
    "item_daily_features = pd.read_csv(rootpath + \"data/item_daily_features.csv\")\n",
    "\n",
    "print(\"All data loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the interactions_train, interactions_test and sample_submmission. I get rid of the columns that will not be usefull like play_duration and video_duration because it is used in the watch_ratio computation, so no need. I alsaw get rid of the time and date. \n",
    "\n",
    "Timestamps is a bit special, in the interactions_train matrix they are valuable because they capture the evolution of user preferences over time rather than treating them as static. They enable recency-based weighting where recent interactions influence recommendations more heavily, and support sequential pattern recognition for time-aware suggestions. Additionally, timestamps provide crucial context that helps differentiate between casual browsing and genuine interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_interactions(big_matrix, small_matrix):\n",
    "    \"\"\"\n",
    "    Create train/test sets including a warm-up phase for cold-start users.\n",
    "    \"\"\"\n",
    "    interactions_train = big_matrix[['user_id', 'video_id', 'watch_ratio', 'timestamp']].copy()\n",
    "\n",
    "    # interactions_test only needs user_id and video_id\n",
    "    interactions_test = small_matrix[['user_id', 'video_id']].copy()\n",
    "\n",
    "    return interactions_train, interactions_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactions train and test dataframes created.\n",
      "(12530806, 4)\n",
      "(4676570, 2)\n"
     ]
    }
   ],
   "source": [
    "interactions_train, interactions_test = create_interactions(big_matrix, small_matrix)\n",
    "print(\"Interactions train and test dataframes created.\")\n",
    "print(interactions_train.shape)\n",
    "print(interactions_test.shape)\n",
    "interactions_train.to_csv(rootpath + \"data/interactions_train.csv\", index=False)\n",
    "interactions_test.to_csv(rootpath + \"data/interactions_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_video_metadata_v2(item_categories, kuairec_caption_category, item_daily_features):\n",
    "    \"\"\"\n",
    "    Create enhanced video metadata with improved negative feedback incorporation\n",
    "    and additional features.\n",
    "    \"\"\"\n",
    "    for df in [item_categories, kuairec_caption_category, item_daily_features]:\n",
    "        if 'video_id' in df.columns:\n",
    "            df['video_id'] = df['video_id'].astype(str)\n",
    "\n",
    "    video_features = item_daily_features.drop_duplicates(subset=['video_id'])[\n",
    "        ['video_id', 'author_id', 'video_duration']\n",
    "    ]\n",
    "\n",
    "    # Define engagement columns\n",
    "    engagement_columns = [\n",
    "        'show_cnt', 'play_cnt', 'play_duration', 'play_progress',\n",
    "        'complete_play_cnt', 'valid_play_cnt', 'long_time_play_cnt', 'short_time_play_cnt',\n",
    "        'like_cnt', 'cancel_like_cnt', 'comment_cnt', 'comment_stay_duration',\n",
    "        'follow_cnt', 'cancel_follow_cnt', 'share_cnt', 'download_cnt',\n",
    "        'report_cnt', 'reduce_similar_cnt', 'collect_cnt', 'cancel_collect_cnt'\n",
    "    ]\n",
    "\n",
    "    agg_metrics = item_daily_features.groupby('video_id')[engagement_columns].mean()\n",
    "\n",
    "    derived_metrics = pd.DataFrame(index=agg_metrics.index)\n",
    "\n",
    "    # Basic engagement metrics\n",
    "    derived_metrics['completion_rate'] = agg_metrics['complete_play_cnt'] / agg_metrics['play_cnt'].replace(0, 1)\n",
    "    derived_metrics['engagement_depth'] = agg_metrics['long_time_play_cnt'] / (\n",
    "        agg_metrics['long_time_play_cnt'] + agg_metrics['short_time_play_cnt']).replace(0, 1)\n",
    "    derived_metrics['validation_ratio'] = agg_metrics['valid_play_cnt'] / agg_metrics['play_cnt'].replace(0, 1)\n",
    "    \n",
    "    # Interaction metrics\n",
    "    derived_metrics['like_ratio'] = agg_metrics['like_cnt'] / agg_metrics['show_cnt'].replace(0, 1)\n",
    "    derived_metrics['like_cancel_ratio'] = agg_metrics['cancel_like_cnt'] / agg_metrics['like_cnt'].replace(0, 1)\n",
    "    derived_metrics['comment_ratio'] = agg_metrics['comment_cnt'] / agg_metrics['show_cnt'].replace(0, 1)\n",
    "    derived_metrics['share_ratio'] = agg_metrics['share_cnt'] / agg_metrics['show_cnt'].replace(0, 1)\n",
    "    derived_metrics['collect_ratio'] = agg_metrics['collect_cnt'] / agg_metrics['show_cnt'].replace(0, 1)\n",
    "    \n",
    "    # Negative feedback metrics\n",
    "    derived_metrics['report_ratio'] = agg_metrics['report_ratio'] = agg_metrics['report_cnt'] / agg_metrics['show_cnt'].replace(0, 1)\n",
    "    derived_metrics['reduce_similar_ratio'] = agg_metrics['reduce_similar_cnt'] / agg_metrics['show_cnt'].replace(0, 1)\n",
    "\n",
    "    # Comprehensive quality score\n",
    "    derived_metrics['quality_score'] = (\n",
    "        derived_metrics['completion_rate'] +\n",
    "        derived_metrics['like_ratio'] * 2 +\n",
    "        derived_metrics['share_ratio'] * 3 +\n",
    "        derived_metrics['collect_ratio'] * 2 -\n",
    "        derived_metrics['like_cancel_ratio'] * 2 -\n",
    "        derived_metrics['report_ratio'] * 5 -\n",
    "        derived_metrics['reduce_similar_ratio'] * 3\n",
    "    )\n",
    "\n",
    "    # Engagement score combining quality and quantity metrics\n",
    "    derived_metrics['engagement_score'] = (\n",
    "        agg_metrics['play_progress'] * \n",
    "        (derived_metrics['completion_rate'] + derived_metrics['engagement_depth'])\n",
    "    )\n",
    "\n",
    "\n",
    "    derived_metrics['follow_impact'] = (\n",
    "        agg_metrics['follow_cnt'] - agg_metrics['cancel_follow_cnt']\n",
    "    ) / agg_metrics['show_cnt'].replace(0, 1)\n",
    "\n",
    "\n",
    "    derived_metrics['retention_impact'] = (\n",
    "        (agg_metrics['play_duration'] / (video_features['video_duration'] * agg_metrics['play_cnt']).replace(0, 1)) + \n",
    "        (agg_metrics['comment_stay_duration'] / 60) / agg_metrics['play_cnt'].replace(0, 1)\n",
    "    )\n",
    "\n",
    "    # Merge video features with derived metrics\n",
    "    video_metadata = video_features.merge(\n",
    "        derived_metrics, left_on='video_id', right_index=True, how='left'\n",
    "    )\n",
    "\n",
    "    # Merge with categorical features\n",
    "    video_metadata = video_metadata.merge(\n",
    "        item_categories[['video_id', 'feat']], on='video_id', how='left'\n",
    "    )\n",
    "\n",
    "    video_metadata = video_metadata.merge(\n",
    "        kuairec_caption_category[['video_id', 'topic_tag', \n",
    "                                'first_level_category_name', 'second_level_category_name', \n",
    "                                'third_level_category_name']], \n",
    "        on='video_id', how='left'\n",
    "    )\n",
    "\n",
    "    # Calculate trending score\n",
    "    daily_metrics = item_daily_features.groupby(['video_id', 'date'])['play_cnt'].sum().reset_index()\n",
    "    if len(daily_metrics['date'].unique()) >= 2:\n",
    "        latest_date = daily_metrics['date'].max()\n",
    "        prev_date = sorted(daily_metrics['date'].unique())[-2]\n",
    "        trend_df = daily_metrics.pivot(index='video_id', columns='date', values='play_cnt').fillna(0)\n",
    "        trend_df['trending_score'] = (trend_df[latest_date] - trend_df[prev_date]) / (trend_df[prev_date] + 1)\n",
    "        video_metadata = video_metadata.merge(\n",
    "            trend_df[['trending_score']], left_on='video_id', right_index=True, how='left'\n",
    "        )\n",
    "    else:\n",
    "        video_metadata['trending_score'] = 0\n",
    "\n",
    "    return video_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video metadata features created.\n"
     ]
    }
   ],
   "source": [
    "video_metadata2 = create_video_metadata_v2(item_categories, captions, item_daily_features)\n",
    "print(\"Video metadata features created.\")\n",
    "video_metadata2.to_csv(rootpath + \"data/video_metadata2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "def process_user_batch(user_batch, user_groups, video_vectors, feature_dimensions):\n",
    "    \"\"\"\n",
    "    Process a batch of users to create user profiles.\n",
    "    Now defined at module level to support multiprocessing.\n",
    "    \"\"\"\n",
    "    batch_profiles = {}\n",
    "    for user_id in user_batch:\n",
    "        if user_id not in user_groups:\n",
    "            continue\n",
    "            \n",
    "        group = user_groups[user_id]\n",
    "        vids = group['video_id'].values\n",
    "        weights = group['watch_ratio'].values\n",
    "        timestamps = group['timestamp'].values\n",
    "\n",
    "        if len(timestamps) > 1:\n",
    "            max_ts = timestamps.max()\n",
    "            min_ts = timestamps.min()\n",
    "            age = (max_ts - timestamps) / (max_ts - min_ts + 1e-6)\n",
    "            recency_weights = np.exp(-2 * age)\n",
    "        else:\n",
    "            recency_weights = np.ones_like(timestamps)\n",
    "        \n",
    "        # Combine watch_ratio and recency\n",
    "        combined_weights = weights * recency_weights\n",
    "        \n",
    "        vectors = []\n",
    "        for i, vid in enumerate(vids):\n",
    "            if vid in video_vectors:\n",
    "                w = combined_weights[i]\n",
    "                # Use high watch ratio as positive signal\n",
    "                if w > 0.6:\n",
    "                    vectors.append(video_vectors[vid] * w)\n",
    "                # Use low watch ratio as negative signal\n",
    "                elif w < 0.2:\n",
    "                    vectors.append(video_vectors[vid] * -0.5)\n",
    "                else:\n",
    "                    vectors.append(video_vectors[vid] * w)\n",
    "        \n",
    "        if vectors:\n",
    "            batch_profiles[user_id] = np.mean(vectors, axis=0)\n",
    "        else:\n",
    "            batch_profiles[user_id] = np.zeros(feature_dimensions)\n",
    "    \n",
    "    return batch_profiles\n",
    "\n",
    "def process_test_batch(test_batch, user_profiles, video_vectors, video_metadata_dict, \n",
    "                       min_quality, quality_range):\n",
    "    \"\"\"\n",
    "    Process a batch of test interactions to generate recommendations.\n",
    "    Now defined at module level to support multiprocessing.\n",
    "    \"\"\"\n",
    "    batch_results = []\n",
    "    for _, row in test_batch.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        video_id = row['video_id']\n",
    "        \n",
    "        if user_id in user_profiles and video_id in video_vectors:\n",
    "            user_vec = user_profiles[user_id].reshape(1, -1)\n",
    "            video_vec = video_vectors[video_id].reshape(1, -1)\n",
    "            \n",
    "            # Compute similarity\n",
    "            similarity = cosine_similarity(user_vec, video_vec)[0][0]\n",
    "            similarity_norm = (similarity + 1) / 2\n",
    "            \n",
    "            # Get quality score\n",
    "            quality_score, trending_score = video_metadata_dict.get(\n",
    "                video_id, (0, 0)\n",
    "            )\n",
    "            \n",
    "            quality_norm = (quality_score - min_quality) / quality_range if quality_range > 0 else 0\n",
    "            \n",
    "            # Apply quality boost\n",
    "            quality_boost = 0.85 + 0.3 * quality_norm\n",
    "            score = float(similarity_norm * quality_boost)\n",
    "            \n",
    "        elif video_id in video_vectors:\n",
    "            # Cold-start: use quality and trending\n",
    "            quality_score, trending_score = video_metadata_dict.get(\n",
    "                video_id, (0, 0)\n",
    "            )\n",
    "            \n",
    "            quality_norm = (quality_score - min_quality) / quality_range if quality_range > 0 else 0\n",
    "            cold_start_weight = 0.2 if user_id not in user_profiles else 0.1\n",
    "            score = float(cold_start_weight * (0.7 * quality_norm + 0.3 * trending_score))\n",
    "        else:\n",
    "            score = 0.0\n",
    "        \n",
    "        batch_results.append({\n",
    "            'user_id': user_id, \n",
    "            'video_id': video_id, \n",
    "            'predicted_score': score\n",
    "        })\n",
    "        \n",
    "    return batch_results\n",
    "\n",
    "def fast_recommendation_system(interactions_train, interactions_test, video_metadata, \n",
    "                              svd_components=50, batch_size=1000, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Fast implementation of recommendation system with fixed multiprocessing support\n",
    "    \"\"\"\n",
    "    # Filter the training set to only include users who are in the test set\n",
    "    # This optimization significantly reduces processing time. Had to do that because too long otherwise\n",
    "    test_users = set(interactions_test['user_id'].unique())\n",
    "    filtered_interactions_train = interactions_train[interactions_train['user_id'].isin(test_users)]\n",
    "    print(f\"Filtered training interactions from {len(interactions_train)} to {len(filtered_interactions_train)} entries\")\n",
    "    \n",
    "    print(\"Step 1: Processing video features\")\n",
    "    \n",
    "    # Process tag features with MultiLabelBinarizer \n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    tag_features = mlb.fit_transform(video_metadata['feat'])\n",
    "    \n",
    "    # Process categorical features\n",
    "    categorical_features = [\n",
    "        'first_level_category_name', 'second_level_category_name', \n",
    "        'third_level_category_name', 'topic_tag'\n",
    "    ]\n",
    "    video_metadata[categorical_features] = video_metadata[categorical_features].fillna('')\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=True)\n",
    "    encoded_cats = encoder.fit_transform(video_metadata[categorical_features])\n",
    "    \n",
    "    # Process numerical features\n",
    "    numerical_features = [\n",
    "        'video_duration', 'aspect_ratio',\n",
    "        'completion_rate', 'engagement_depth', 'validation_ratio',\n",
    "        'like_ratio', 'comment_ratio', 'share_ratio', 'collect_ratio',\n",
    "        'quality_score', 'engagement_score', 'follow_impact',\n",
    "        'retention_impact', 'trending_score'\n",
    "    ]\n",
    "    \n",
    "    # Scale\n",
    "    scaler = StandardScaler()\n",
    "    numerical_data = scaler.fit_transform(video_metadata[numerical_features].fillna(0))\n",
    "    \n",
    "    # Process author features\n",
    "    author_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=True)\n",
    "    author_encoded = author_encoder.fit_transform(video_metadata[['author_id']])\n",
    "    \n",
    "    print(\"Step 2: Applying dimensionality reduction\")\n",
    "\n",
    "    svd_cat = TruncatedSVD(n_components=min(svd_components, encoded_cats.shape[1]-1), random_state=42)\n",
    "    cat_reduced = svd_cat.fit_transform(encoded_cats)\n",
    "    print(f\"Category features explained variance: {sum(svd_cat.explained_variance_ratio_):.2f}\")\n",
    "    \n",
    "    if tag_features.shape[1] > 0:\n",
    "        svd_tag = TruncatedSVD(n_components=min(svd_components, tag_features.shape[1]-1), random_state=42)\n",
    "        tag_reduced = svd_tag.fit_transform(tag_features)\n",
    "        print(f\"Tag features explained variance: {sum(svd_tag.explained_variance_ratio_):.2f}\")\n",
    "    else:\n",
    "        tag_reduced = np.zeros((video_metadata.shape[0], 1))\n",
    "    \n",
    "    author_components = min(svd_components//2, author_encoded.shape[1]-1)\n",
    "    if author_components > 0:\n",
    "        svd_author = TruncatedSVD(n_components=author_components, random_state=42)\n",
    "        author_reduced = svd_author.fit_transform(author_encoded) * 0.3  # Reduced weight for author\n",
    "    else:\n",
    "        author_reduced = np.zeros((video_metadata.shape[0], 1))\n",
    "    \n",
    "    # Combine all features\n",
    "    video_feature_vectors = np.hstack([\n",
    "        cat_reduced, \n",
    "        tag_reduced, \n",
    "        numerical_data,\n",
    "        author_reduced\n",
    "    ])\n",
    "    \n",
    "    video_id_to_index = {vid: idx for idx, vid in enumerate(video_metadata['video_id'])}\n",
    "    \n",
    "    video_metadata_dict = dict(zip(video_metadata['video_id'], zip(\n",
    "        video_metadata['quality_score'],\n",
    "        video_metadata['trending_score']\n",
    "    )))\n",
    "    \n",
    "    video_vectors = {vid: video_feature_vectors[idx] for vid, idx in video_id_to_index.items()}\n",
    "    \n",
    "    print(\"Step 3: Building user profiles\")\n",
    "\n",
    "    user_profiles = {}\n",
    "    user_groups = dict(list(filtered_interactions_train.groupby('user_id')))\n",
    "    \n",
    "    user_ids = list(user_groups.keys())\n",
    "    num_cpus = multiprocessing.cpu_count() if n_jobs <= 0 else min(n_jobs, multiprocessing.cpu_count())\n",
    "    batch_size = max(1, len(user_ids) // (num_cpus * 2))\n",
    "    \n",
    "    user_batches = [user_ids[i:i + batch_size] for i in range(0, len(user_ids), batch_size)]\n",
    "    print(f\"Processing {len(user_ids)} users in {len(user_batches)} batches using {num_cpus} processes\")\n",
    "    \n",
    "    with multiprocessing.Pool(processes=num_cpus) as pool:\n",
    "        feature_dimensions = video_feature_vectors.shape[1]\n",
    "        results = list(tqdm(\n",
    "            pool.starmap(\n",
    "                process_user_batch, \n",
    "                [(batch, user_groups, video_vectors, feature_dimensions) for batch in user_batches]\n",
    "            ),\n",
    "            total=len(user_batches),\n",
    "            desc=\"Building user profiles\"\n",
    "        ))\n",
    "    \n",
    "    for batch_result in results:\n",
    "        user_profiles.update(batch_result)\n",
    "    \n",
    "    print(f\"Built profiles for {len(user_profiles)} users\")\n",
    "    \n",
    "\n",
    "    print(\"Step 4: Computing recommendations\")\n",
    "    \n",
    "    min_quality = min(q for q, _ in video_metadata_dict.values())\n",
    "    max_quality = max(q for q, _ in video_metadata_dict.values())\n",
    "    quality_range = max_quality - min_quality\n",
    "    \n",
    "    test_batches = [interactions_test[i:i + batch_size] for i in range(0, len(interactions_test), batch_size)]\n",
    "    \n",
    "    with multiprocessing.Pool(processes=num_cpus) as pool:\n",
    "        batch_results = list(tqdm(\n",
    "            pool.starmap(\n",
    "                process_test_batch,\n",
    "                [(batch, user_profiles, video_vectors, video_metadata_dict, min_quality, quality_range) \n",
    "                 for batch in test_batches]\n",
    "            ),\n",
    "            total=len(test_batches),\n",
    "            desc=\"Calculating recommendation scores\"\n",
    "        ))\n",
    "    \n",
    "    # Combine all results\n",
    "    all_results = []\n",
    "    for batch in batch_results:\n",
    "        all_results.extend(batch)\n",
    "    \n",
    "    recommendations = pd.DataFrame(all_results)\n",
    "    recommendations['predicted_score'] = np.clip(recommendations['predicted_score'], 0, 1)\n",
    "    \n",
    "    print(\"Recommendation generation complete!\")\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "rootpath=\"./data_final_project/KuaiRec 2.0/\"\n",
    "video_metadata2 = pd.read_csv(rootpath + \"data/video_metadata2.csv\")\n",
    "interactions_train = pd.read_csv(rootpath + \"data/interactions_train.csv\")\n",
    "interactions_test = pd.read_csv(rootpath + \"data/interactions_test.csv\")\n",
    "\n",
    "import ast\n",
    "interactions_test['video_id'] = interactions_test['video_id'].astype(int)\n",
    "interactions_train['video_id'] = interactions_train['video_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadata2[\"video_id\"] = video_metadata2[\"video_id\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered training interactions from 12530806 to 571061 entries\n",
      "Step 1: Processing video features\n",
      "Step 2: Applying dimensionality reduction\n",
      "Category features explained variance: 0.71\n",
      "Step 3: Building user profiles\n",
      "Processing 1411 users in 33 batches using 16 processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building user profiles: 100%|██████████| 33/33 [00:00<00:00, 203547.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built profiles for 1411 users\n",
      "Step 4: Computing recommendations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating recommendation scores: 100%|██████████| 106286/106286 [00:00<00:00, 3853764.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation generation complete!\n",
      "Recommendations generated.\n",
      "   user_id  video_id  predicted_score\n",
      "0       14       148         0.951569\n",
      "1       14       183         1.000000\n",
      "2       14      3649         0.978810\n",
      "3       14      5262         1.000000\n",
      "4       14      8234         0.826265\n"
     ]
    }
   ],
   "source": [
    "filtered_interactions_train = interactions_train[interactions_train['user_id'].isin(interactions_test['user_id'])]\n",
    "recommendations = fast_recommendation_system(interactions_train, interactions_test, video_metadata2)\n",
    "print(\"Recommendations generated.\")\n",
    "print(recommendations.head())\n",
    "recommendations.to_csv(rootpath + \"data/recommendations3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  video_id  predicted_score\n",
      "0       14       148         0.966219\n",
      "1       14       183         1.000000\n",
      "2       14      3649         0.947657\n",
      "3       14      5262         1.000000\n",
      "4       14      8234         0.907958\n",
      "5       14      6789         0.981326\n",
      "6       14      1963         0.937952\n",
      "7       14       175         0.722779\n",
      "8       14      1973         1.000000\n",
      "9       14       171         1.000000\n"
     ]
    }
   ],
   "source": [
    "print(recommendations.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_313329/1090879296.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  recommendation_top10 = recommendation_df.groupby('user_id', group_keys=False).apply(\n",
      "/tmp/ipykernel_313329/1090879296.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  truth_top10 = truth_df.groupby('user_id', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "\n",
    "rootpath=\"./data_final_project/KuaiRec 2.0/\"\n",
    "recommendation_df = pd.read_csv(rootpath + 'data/recommendations3.csv')\n",
    "truth_df = pd.read_csv(rootpath + 'data/small_matrix.csv')\n",
    "\n",
    "recommendation_top10 = recommendation_df.groupby('user_id', group_keys=False).apply(\n",
    "    lambda x: x.nlargest(50, 'predicted_score'))\n",
    "\n",
    "truth_top10 = truth_df.groupby('user_id', group_keys=False).apply(\n",
    "    lambda x: x.nlargest(50, 'watch_ratio'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(recommended, relevant, k):\n",
    "    \"\"\"Calculate precision@k (order-agnostic)\"\"\"\n",
    "    recommended_set = set(recommended[:k])\n",
    "    relevant_set = set(relevant)\n",
    "    hits = len(recommended_set.intersection(relevant_set))\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(recommended, relevant, k):\n",
    "    \"\"\"Calculate recall@k (order-agnostic)\"\"\"\n",
    "    recommended_set = set(recommended[:k])\n",
    "    relevant_set = set(relevant)\n",
    "    hits = len(recommended_set.intersection(relevant_set))\n",
    "    return hits / len(relevant_set) if relevant_set else 0\n",
    "\n",
    "def f1_score_at_k(recommended, relevant, k):\n",
    "    \"\"\"Calculate F1 score@k (order-agnostic)\"\"\"\n",
    "    prec = precision_at_k(recommended, relevant, k)\n",
    "    rec = recall_at_k(recommended, relevant, k)\n",
    "    return 2 * (prec * rec) / (prec + rec) if (prec + rec) > 0 else 0\n",
    "\n",
    "# Additional set-based metrics\n",
    "def jaccard_similarity(recommended, relevant, k):\n",
    "    \"\"\"Calculate Jaccard similarity (order-agnostic)\"\"\"\n",
    "    recommended_set = set(recommended[:k])\n",
    "    relevant_set = set(relevant)\n",
    "    intersection = len(recommended_set.intersection(relevant_set))\n",
    "    union = len(recommended_set.union(relevant_set))\n",
    "    return intersection / union if union > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision@50: 0.0479\n",
      "Average Recall@50: 0.0479\n",
      "Average F1@50: 0.0479\n",
      "Average Jaccard Similarity: 0.0250\n"
     ]
    }
   ],
   "source": [
    "k = 50\n",
    "user_ids = recommendation_top10['user_id'].unique()\n",
    "\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "jaccard_scores = []\n",
    "\n",
    "for user in user_ids:\n",
    "    rec_videos = recommendation_top10[recommendation_top10['user_id'] == user]['video_id'].tolist()\n",
    "    true_videos = truth_top10[truth_top10['user_id'] == user]['video_id'].tolist()\n",
    "    \n",
    "    precision_scores.append(precision_at_k(rec_videos, true_videos, k))\n",
    "    recall_scores.append(recall_at_k(rec_videos, true_videos, k))\n",
    "    f1_scores.append(f1_score_at_k(rec_videos, true_videos, k))\n",
    "    jaccard_scores.append(jaccard_similarity(rec_videos, true_videos, k))\n",
    "\n",
    "\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_recall = np.mean(recall_scores)\n",
    "average_f1 = np.mean(f1_scores)\n",
    "average_jaccard = np.mean(jaccard_scores)\n",
    "\n",
    "print(f\"Average Precision@{k}: {average_precision:.4f}\")\n",
    "print(f\"Average Recall@{k}: {average_recall:.4f}\")\n",
    "print(f\"Average F1@{k}: {average_f1:.4f}\")\n",
    "print(f\"Average Jaccard Similarity: {average_jaccard:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata_kernel",
   "language": "python",
   "name": "bigdata_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
